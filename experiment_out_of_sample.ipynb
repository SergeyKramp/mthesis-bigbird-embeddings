{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from data.dataprocessor import DataProcessor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from feature_extractors.normal_feature_extractor import NormalFeatureExtractor\n",
    "from feature_extractors.transformer_feature_extractor import TransformerFeatureExtractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprocessor = DataProcessor('google/bigbird-roberta-base')\n",
    "\n",
    "dataprocessor.discover_chunks('data/balanced/seed_42/europe_data')\n",
    "\n",
    "europe_data, _ = dataprocessor.get_train_test_datasets(train_size=1)\n",
    "\n",
    "europe_df = europe_data.get_dataframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on `non_europe` Data and Evaluate on `europe` Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features from `europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks were not used when initializing BigBirdModel: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word ngram features...\n",
      "Creating char ngram features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating edit distance: 100%|██████████| 5254/5254 [01:28<00:00, 59.35it/s]\n",
      "Extracting Substitution Features:  13%|█▎        | 678/5254 [00:13<01:27, 52.10it/s]"
     ]
    }
   ],
   "source": [
    "normal_feature_extractor = pickle.load(open('pickles/normal_feature_extractor_seed_42_chunks.pkl', 'rb'))\n",
    "big_bird_fine_tuned_non_europe_feature_extractor = TransformerFeatureExtractor('fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks', 2048)\n",
    "\n",
    "def insert_grammar_features(all_features: np.array, grammar_features: np.array) -> np.array:\n",
    "    return np.concatenate((all_features[:, :2300], grammar_features, all_features[:, 2300:]), axis=1)\n",
    "\n",
    "X_normal_europe = normal_feature_extractor.transform(europe_df.text.to_list(), grammar_mistakes=False).to_numpy()\n",
    "grammar_features = normal_feature_extractor.get_grammar_features(europe_df.text.to_list())\n",
    "\n",
    "X_normal_europe = insert_grammar_features(X_normal_europe, grammar_features)\n",
    "\n",
    "X_bigbird = big_bird_fine_tuned_non_europe_feature_extractor.transform(europe_df.text.to_list())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import `non_europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_X_normal_chunks.pkl', 'rb')).to_numpy()\n",
    "\n",
    "X_bigbird_fine_tuned_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_X_bigbird_fine_tuned_chunks.pkl', 'rb'))\n",
    "\n",
    "y_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_y_chunks.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifiers on `non_europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       119301     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16568D+05    |proj g|=  6.11613D+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  7.78330D+04    |proj g|=  5.76286D+04\n",
      "\n",
      "At iterate  100    f=  6.33450D+04    |proj g|=  1.71410D+04\n",
      "\n",
      "At iterate  150    f=  5.59018D+04    |proj g|=  1.29523D+04\n",
      "\n",
      "At iterate  200    f=  4.99981D+04    |proj g|=  2.92420D+04\n",
      "\n",
      "At iterate  250    f=  4.64432D+04    |proj g|=  1.84267D+04\n",
      "\n",
      "At iterate  300    f=  4.32104D+04    |proj g|=  1.63115D+04\n",
      "\n",
      "At iterate  350    f=  3.89927D+04    |proj g|=  1.38743D+04\n",
      "\n",
      "At iterate  400    f=  3.52083D+04    |proj g|=  1.22159D+04\n",
      "\n",
      "At iterate  450    f=  3.26309D+04    |proj g|=  7.90397D+03\n",
      "\n",
      "At iterate  500    f=  3.04920D+04    |proj g|=  9.82527D+03\n",
      "\n",
      "At iterate  550    f=  2.82607D+04    |proj g|=  5.46332D+03\n",
      "\n",
      "At iterate  600    f=  2.62642D+04    |proj g|=  1.22055D+04\n",
      "\n",
      "At iterate  650    f=  2.45569D+04    |proj g|=  8.67473D+03\n",
      "\n",
      "At iterate  700    f=  2.25384D+04    |proj g|=  5.04658D+03\n",
      "\n",
      "At iterate  750    f=  2.14864D+04    |proj g|=  7.92410D+03\n",
      "\n",
      "At iterate  800    f=  2.03114D+04    |proj g|=  5.32900D+03\n",
      "\n",
      "At iterate  850    f=  1.91628D+04    |proj g|=  1.04073D+04\n",
      "\n",
      "At iterate  900    f=  1.79030D+04    |proj g|=  8.97544D+03\n",
      "\n",
      "At iterate  950    f=  1.67127D+04    |proj g|=  5.03066D+03\n",
      "\n",
      "At iterate 1000    f=  1.57009D+04    |proj g|=  3.63860D+03\n",
      "\n",
      "At iterate 1050    f=  1.50625D+04    |proj g|=  2.65893D+03\n",
      "\n",
      "At iterate 1100    f=  1.45835D+04    |proj g|=  4.09073D+03\n",
      "\n",
      "At iterate 1150    f=  1.40624D+04    |proj g|=  3.76397D+03\n",
      "\n",
      "At iterate 1200    f=  1.35331D+04    |proj g|=  1.96726D+03\n",
      "\n",
      "At iterate 1250    f=  1.29700D+04    |proj g|=  6.43732D+03\n",
      "\n",
      "At iterate 1300    f=  1.23867D+04    |proj g|=  6.32042D+03\n",
      "\n",
      "At iterate 1350    f=  1.18329D+04    |proj g|=  3.79594D+03\n",
      "\n",
      "At iterate 1400    f=  1.13116D+04    |proj g|=  2.23923D+03\n",
      "\n",
      "At iterate 1450    f=  1.08131D+04    |proj g|=  3.38302D+03\n",
      "\n",
      "At iterate 1500    f=  1.04299D+04    |proj g|=  4.41562D+03\n",
      "\n",
      "At iterate 1550    f=  9.97417D+03    |proj g|=  2.62706D+03\n",
      "\n",
      "At iterate 1600    f=  9.57727D+03    |proj g|=  6.42859D+03\n",
      "\n",
      "At iterate 1650    f=  9.18987D+03    |proj g|=  3.27484D+03\n",
      "\n",
      "At iterate 1700    f=  8.78419D+03    |proj g|=  3.67658D+03\n",
      "\n",
      "At iterate 1750    f=  8.43126D+03    |proj g|=  4.06859D+03\n",
      "\n",
      "At iterate 1800    f=  8.07298D+03    |proj g|=  2.30785D+03\n",
      "\n",
      "At iterate 1850    f=  7.73459D+03    |proj g|=  2.76969D+03\n",
      "\n",
      "At iterate 1900    f=  7.41463D+03    |proj g|=  3.51149D+03\n",
      "\n",
      "At iterate 1950    f=  7.08593D+03    |proj g|=  3.68140D+03\n",
      "\n",
      "At iterate 2000    f=  6.76604D+03    |proj g|=  3.23871D+03\n",
      "\n",
      "At iterate 2050    f=  6.44818D+03    |proj g|=  3.32849D+03\n",
      "\n",
      "At iterate 2100    f=  6.14776D+03    |proj g|=  1.49210D+03\n",
      "\n",
      "At iterate 2150    f=  5.87377D+03    |proj g|=  2.05744D+03\n",
      "\n",
      "At iterate 2200    f=  5.59995D+03    |proj g|=  8.58916D+02\n",
      "\n",
      "At iterate 2250    f=  5.30270D+03    |proj g|=  2.40345D+03\n",
      "\n",
      "At iterate 2300    f=  5.04736D+03    |proj g|=  3.07985D+03\n",
      "\n",
      "At iterate 2350    f=  4.83139D+03    |proj g|=  2.85276D+03\n",
      "\n",
      "At iterate 2400    f=  4.64538D+03    |proj g|=  1.50734D+03\n",
      "\n",
      "At iterate 2450    f=  4.47917D+03    |proj g|=  1.29659D+03\n",
      "\n",
      "At iterate 2500    f=  4.34360D+03    |proj g|=  7.64961D+02\n",
      "\n",
      "At iterate 2550    f=  4.21384D+03    |proj g|=  1.35018D+03\n",
      "\n",
      "At iterate 2600    f=  4.10929D+03    |proj g|=  5.18508D+02\n",
      "\n",
      "At iterate 2650    f=  4.01652D+03    |proj g|=  1.40331D+03\n",
      "\n",
      "At iterate 2700    f=  3.93430D+03    |proj g|=  9.91945D+02\n",
      "\n",
      "At iterate 2750    f=  3.87052D+03    |proj g|=  5.80190D+02\n",
      "\n",
      "At iterate 2800    f=  3.81219D+03    |proj g|=  7.75496D+02\n",
      "\n",
      "At iterate 2850    f=  3.76255D+03    |proj g|=  3.61528D+02\n",
      "\n",
      "At iterate 2900    f=  3.72733D+03    |proj g|=  4.81220D+02\n",
      "\n",
      "At iterate 2950    f=  3.69444D+03    |proj g|=  5.08226D+02\n",
      "\n",
      "At iterate 3000    f=  3.66748D+03    |proj g|=  4.02637D+02\n",
      "\n",
      "At iterate 3050    f=  3.64111D+03    |proj g|=  3.30677D+02\n",
      "\n",
      "At iterate 3100    f=  3.61827D+03    |proj g|=  7.61312D+02\n",
      "\n",
      "At iterate 3150    f=  3.59643D+03    |proj g|=  2.39054D+02\n",
      "\n",
      "At iterate 3200    f=  3.57744D+03    |proj g|=  5.66778D+02\n",
      "\n",
      "At iterate 3250    f=  3.56069D+03    |proj g|=  2.43460D+02\n",
      "\n",
      "At iterate 3300    f=  3.54369D+03    |proj g|=  4.23023D+02\n",
      "\n",
      "At iterate 3350    f=  3.53037D+03    |proj g|=  3.95717D+02\n",
      "\n",
      "At iterate 3400    f=  3.51662D+03    |proj g|=  2.75020D+02\n",
      "\n",
      "At iterate 3450    f=  3.50433D+03    |proj g|=  2.84903D+02\n",
      "\n",
      "At iterate 3500    f=  3.49307D+03    |proj g|=  2.31384D+02\n",
      "\n",
      "At iterate 3550    f=  3.48156D+03    |proj g|=  1.75313D+02\n",
      "\n",
      "At iterate 3600    f=  3.47310D+03    |proj g|=  2.31254D+02\n",
      "\n",
      "At iterate 3650    f=  3.46498D+03    |proj g|=  1.86199D+02\n",
      "\n",
      "At iterate 3700    f=  3.45841D+03    |proj g|=  2.88817D+02\n",
      "\n",
      "At iterate 3750    f=  3.45199D+03    |proj g|=  2.32471D+02\n",
      "\n",
      "At iterate 3800    f=  3.44560D+03    |proj g|=  3.50921D+02\n",
      "\n",
      "At iterate 3850    f=  3.44038D+03    |proj g|=  1.24658D+02\n",
      "\n",
      "At iterate 3900    f=  3.43476D+03    |proj g|=  2.86158D+02\n",
      "\n",
      "At iterate 3950    f=  3.43077D+03    |proj g|=  2.79452D+02\n",
      "\n",
      "At iterate 4000    f=  3.42705D+03    |proj g|=  1.42690D+02\n",
      "\n",
      "At iterate 4050    f=  3.42300D+03    |proj g|=  1.51536D+02\n",
      "\n",
      "At iterate 4100    f=  3.41935D+03    |proj g|=  1.91693D+02\n",
      "\n",
      "At iterate 4150    f=  3.41465D+03    |proj g|=  1.39360D+02\n",
      "\n",
      "At iterate 4200    f=  3.41138D+03    |proj g|=  1.65940D+02\n",
      "\n",
      "At iterate 4250    f=  3.40747D+03    |proj g|=  1.00590D+02\n",
      "\n",
      "At iterate 4300    f=  3.40442D+03    |proj g|=  1.19544D+02\n",
      "\n",
      "At iterate 4350    f=  3.40175D+03    |proj g|=  1.39775D+02\n",
      "\n",
      "At iterate 4400    f=  3.39980D+03    |proj g|=  1.74862D+02\n",
      "\n",
      "At iterate 4450    f=  3.39756D+03    |proj g|=  9.15424D+01\n",
      "\n",
      "At iterate 4500    f=  3.39556D+03    |proj g|=  9.31548D+01\n",
      "\n",
      "At iterate 4550    f=  3.39374D+03    |proj g|=  1.12452D+02\n",
      "\n",
      "At iterate 4600    f=  3.39212D+03    |proj g|=  6.21828D+01\n",
      "\n",
      "At iterate 4650    f=  3.39065D+03    |proj g|=  1.67754D+02\n",
      "\n",
      "At iterate 4700    f=  3.38916D+03    |proj g|=  8.19875D+01\n",
      "\n",
      "At iterate 4750    f=  3.38704D+03    |proj g|=  1.31570D+02\n",
      "\n",
      "At iterate 4800    f=  3.38443D+03    |proj g|=  2.33864D+02\n",
      "\n",
      "At iterate 4850    f=  3.38170D+03    |proj g|=  1.05836D+02\n",
      "\n",
      "At iterate 4900    f=  3.37854D+03    |proj g|=  7.03293D+01\n",
      "\n",
      "At iterate 4950    f=  3.37620D+03    |proj g|=  1.32607D+02\n",
      "\n",
      "At iterate 5000    f=  3.37373D+03    |proj g|=  3.11486D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****   5000   5307      1     0     0   3.115D+02   3.374D+03\n",
      "  F =   3373.7273109154721     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        17687     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16568D+05    |proj g|=  5.21095D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergey/.pyenv/versions/3.7.0/envs/sergey_thesis/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 22.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.60509D+04    |proj g|=  1.88118D+02\n",
      "\n",
      "At iterate  100    f=  3.32251D+04    |proj g|=  8.77817D+01\n",
      "\n",
      "At iterate  150    f=  3.23217D+04    |proj g|=  4.02327D+01\n",
      "\n",
      "At iterate  200    f=  3.20197D+04    |proj g|=  6.21525D+01\n",
      "\n",
      "At iterate  250    f=  3.19074D+04    |proj g|=  2.38797D+01\n",
      "\n",
      "At iterate  300    f=  3.18625D+04    |proj g|=  1.94149D+01\n",
      "\n",
      "At iterate  350    f=  3.18436D+04    |proj g|=  2.98009D+01\n",
      "\n",
      "At iterate  400    f=  3.18351D+04    |proj g|=  1.75526D+01\n",
      "\n",
      "At iterate  450    f=  3.18299D+04    |proj g|=  1.61658D+01\n",
      "\n",
      "At iterate  500    f=  3.18268D+04    |proj g|=  1.02521D+01\n",
      "\n",
      "At iterate  550    f=  3.18246D+04    |proj g|=  3.30755D+00\n",
      "\n",
      "At iterate  600    f=  3.18230D+04    |proj g|=  2.24186D+00\n",
      "\n",
      "At iterate  650    f=  3.18216D+04    |proj g|=  1.14586D+01\n",
      "\n",
      "At iterate  700    f=  3.18204D+04    |proj g|=  2.79345D+00\n",
      "\n",
      "At iterate  750    f=  3.18193D+04    |proj g|=  3.60076D+00\n",
      "\n",
      "At iterate  800    f=  3.18183D+04    |proj g|=  1.76230D+01\n",
      "\n",
      "At iterate  850    f=  3.18176D+04    |proj g|=  4.90139D+00\n",
      "\n",
      "At iterate  900    f=  3.18169D+04    |proj g|=  2.90868D+00\n",
      "\n",
      "At iterate  950    f=  3.18164D+04    |proj g|=  2.07116D+00\n",
      "\n",
      "At iterate 1000    f=  3.18160D+04    |proj g|=  8.89574D-01\n",
      "\n",
      "At iterate 1050    f=  3.18159D+04    |proj g|=  8.51357D+00\n",
      "\n",
      "At iterate 1100    f=  3.18158D+04    |proj g|=  1.22915D+00\n",
      "\n",
      "At iterate 1150    f=  3.18157D+04    |proj g|=  5.44184D-01\n",
      "\n",
      "At iterate 1200    f=  3.18157D+04    |proj g|=  7.08399D-01\n",
      "\n",
      "At iterate 1250    f=  3.18157D+04    |proj g|=  2.09984D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "17687   1292   1327      1     0     0   1.260D+00   3.182D+04\n",
      "  F =   31815.654759992576     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "clf_normal_non_europe = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_normal_non_europe, y_non_europe)\n",
    "clf_bigbird_non_europe = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_bigbird_fine_tuned_non_europe, y_non_europe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on `europe` Data with `non_europe` Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy normal Europe: 0.04701180053292729\n",
      "Accuracy Big Bird fine-tuned Europe: 0.04225352112676056\n"
     ]
    }
   ],
   "source": [
    "pred_normal_europe = clf_normal_non_europe.predict(X_normal_europe)\n",
    "pred_bigbird_europe = clf_bigbird_non_europe.predict(X_bigbird_fine_tuned_europe)\n",
    "\n",
    "accuracy_normal_europe = accuracy_score(europe_df['label'], pred_normal_europe)\n",
    "accuracy_bigbird_europe = accuracy_score(europe_df['label'], pred_bigbird_europe)\n",
    "\n",
    "\n",
    "print(f'Accuracy normal Europe: {accuracy_normal_europe}')\n",
    "print(f'Accuracy Big Bird fine-tuned Europe: {accuracy_bigbird_europe}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on `europe` Data and Evaluate on `europe` Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a normal feature extractor on the `europe` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Vectorizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discovering Substitutions: 100%|██████████| 5254/5254 [01:24<00:00, 62.05it/s]\n",
      "Discovering Grammar Mistakes: 100%|██████████| 5254/5254 [2:15:49<00:00,  1.55s/it]  \n",
      "Discovering POS Ngrams: 100%|██████████| 5254/5254 [06:51<00:00, 12.76it/s]\n"
     ]
    }
   ],
   "source": [
    "normal_feature_extractor = NormalFeatureExtractor()\n",
    "normal_feature_extractor.fit(europe_df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/normal_feature_extractor_europe.pkl', 'wb') as f:\n",
    "    pickle.dump(normal_feature_extractor, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word ngram features...\n",
      "Creating char ngram features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating edit distance: 100%|██████████| 5254/5254 [01:20<00:00, 65.36it/s]\n",
      "Extracting Substitution Features: 100%|██████████| 5254/5254 [01:32<00:00, 56.90it/s]\n",
      "Extracting Grammar Features: 100%|██████████| 5254/5254 [00:22<00:00, 231.40it/s]\n",
      "Extracting Function Word Features: 5254it [00:54, 97.04it/s] \n",
      "Extracting POS Features: 5254it [07:39, 11.44it/s]\n",
      "Extracting Average Sentence Length: 100%|██████████| 5254/5254 [00:01<00:00, 3461.62it/s]\n"
     ]
    }
   ],
   "source": [
    "X_normal_europe = normal_feature_extractor.transform(europe_df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/pickled_datasets/seed_42/X_normal_europe.pkl', 'wb') as f:\n",
    "    pickle.dump(X_normal_europe, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4531 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Extracting features: 100%|██████████| 5254/5254 [20:01<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "bigbird_feature_extractor = TransformerFeatureExtractor('google/bigbird-roberta-base', 2048)\n",
    "X_bigbird_europe = bigbird_feature_extractor.transform(europe_df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/pickled_datasets/seed_42/X_bigbird_europe.pkl', 'wb') as f:\n",
    "    pickle.dump(X_bigbird_europe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks were not used when initializing BigBirdModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4531 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Extracting features: 100%|██████████| 5254/5254 [22:59<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "bigbird_non_europe_fine_tuned_feature_extractor = TransformerFeatureExtractor('fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks', 2048)\n",
    "X_bigbird_fine_tuned_europe = bigbird_non_europe_fine_tuned_feature_extractor.transform(europe_df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/pickled_datasets/seed_42/X_bigbird_fine_tuned_europe.pkl', 'wb') as f:\n",
    "    pickle.dump(X_bigbird_fine_tuned_europe, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_europe_train = X_normal_europe[:int(len(X_normal_europe)*0.8)]\n",
    "X_normal_europe_test = X_normal_europe[int(len(X_normal_europe)*0.8):]\n",
    "\n",
    "X_bigbird_europe_train = X_bigbird_europe[:int(len(X_bigbird_europe)*0.8)]\n",
    "X_bigbird_europe_test = X_bigbird_europe[int(len(X_bigbird_europe)*0.8):]\n",
    "\n",
    "X_bigbird_fine_tuned_europe_train = X_bigbird_fine_tuned_europe[:int(len(X_bigbird_fine_tuned_europe)*0.8)]\n",
    "X_bigbird_fine_tuned_europe_test = X_bigbird_fine_tuned_europe[int(len(X_bigbird_fine_tuned_europe)*0.8):]\n",
    "\n",
    "y_europe_train = europe_df.label[:int(len(europe_df)*0.8)]\n",
    "y_europe_test = europe_df.label[int(len(europe_df)*0.8):]\n",
    "\n",
    "clf_normal_europe = LogisticRegression(random_state=seed, max_iter=10000).fit(X_normal_europe_train, y_europe_train)\n",
    "clf_bigbird_europe = LogisticRegression(random_state=seed, max_iter=10000).fit(X_bigbird_europe_train, y_europe_train)\n",
    "clf_bigbird_fine_tuned_europe = LogisticRegression(random_state=seed, max_iter=10000).fit(X_bigbird_fine_tuned_europe_train, y_europe_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on `europe` Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21027592768791628, 0.7678401522359658, 0.857278782112274)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_normal_europe = clf_normal_europe.predict(X_normal_europe_test)\n",
    "pred_bigbird_europe = clf_bigbird_europe.predict(X_bigbird_europe_test)\n",
    "pred_bigbird_fine_tuned_europe = clf_bigbird_fine_tuned_europe.predict(X_bigbird_fine_tuned_europe_test)\n",
    "\n",
    "accuracy_normal = accuracy_score(y_europe_test, pred_normal_europe)\n",
    "accuracy_bigbird = accuracy_score(y_europe_test, pred_bigbird_europe)\n",
    "accuracy_bigbird_fine_tuned = accuracy_score(y_europe_test, pred_bigbird_fine_tuned_europe)\n",
    "\n",
    "accuracy_normal, accuracy_bigbird, accuracy_bigbird_fine_tuned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sergey_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
