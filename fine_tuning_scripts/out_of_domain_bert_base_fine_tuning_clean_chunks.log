2023-04-11 11:31:10,832 - INFO - Loaded fine-tune dataset
2023-04-11 11:31:10,832 - INFO - Initializing fine-tune dataset
2023-04-11 11:34:18,285 - INFO - Extracted encodings and labels from chunks and initialized dataset
2023-04-11 11:34:20,134 - INFO - Split fine-tune data to fine-tune and validation datasets
2023-04-11 11:34:22,835 - INFO - Training...
2023-04-11 11:34:22,835 - INFO - ======== Epoch 1 / 3 ========
2023-04-11 11:42:18,564 - INFO -   Batch 1,000  of  13,700.    Elapsed: 0:07:56.      Average Loss: 3.1615
2023-04-11 11:50:18,075 - INFO -   Batch 2,000  of  13,700.    Elapsed: 0:15:55.      Average Loss: 3.146
2023-04-11 11:58:17,744 - INFO -   Batch 3,000  of  13,700.    Elapsed: 0:23:55.      Average Loss: 3.1074
2023-04-11 12:06:19,351 - INFO -   Batch 4,000  of  13,700.    Elapsed: 0:31:57.      Average Loss: 2.9974
2023-04-11 12:14:20,013 - INFO -   Batch 5,000  of  13,700.    Elapsed: 0:39:57.      Average Loss: 2.9168
2023-04-11 12:22:20,619 - INFO -   Batch 6,000  of  13,700.    Elapsed: 0:47:58.      Average Loss: 2.8769
2023-04-11 12:30:21,679 - INFO -   Batch 7,000  of  13,700.    Elapsed: 0:55:59.      Average Loss: 2.806
2023-04-11 12:38:21,817 - INFO -   Batch 8,000  of  13,700.    Elapsed: 1:03:59.      Average Loss: 2.721
2023-04-11 12:46:21,654 - INFO -   Batch 9,000  of  13,700.    Elapsed: 1:11:59.      Average Loss: 2.6413
2023-04-11 12:54:22,740 - INFO -   Batch 10,000  of  13,700.    Elapsed: 1:20:00.      Average Loss: 2.5775
2023-04-11 13:02:22,082 - INFO -   Batch 11,000  of  13,700.    Elapsed: 1:27:59.      Average Loss: 2.5442
2023-04-11 13:10:22,797 - INFO -   Batch 12,000  of  13,700.    Elapsed: 1:36:00.      Average Loss: 2.515
2023-04-11 13:18:22,899 - INFO -   Batch 13,000  of  13,700.    Elapsed: 1:44:00.      Average Loss: 2.4607
2023-04-11 13:23:58,074 - INFO -   Epoch Average Training Loss: 2.46
2023-04-11 13:23:58,074 - INFO -   Training epoch took: 1:49:35
2023-04-11 13:23:58,074 - INFO - Running Validation...
2023-04-11 13:28:42,787 - INFO -   Average Validation Loss: 2.06
2023-04-11 13:28:42,787 - INFO -   Validation took: 0:04:45
2023-04-11 13:28:42,787 - INFO - ======== Epoch 2 / 3 ========
2023-04-11 13:36:44,705 - INFO -   Batch 1,000  of  13,700.    Elapsed: 0:08:02.      Average Loss: 2.1997
2023-04-11 13:44:45,579 - INFO -   Batch 2,000  of  13,700.    Elapsed: 0:16:03.      Average Loss: 2.058
2023-04-11 13:52:45,496 - INFO -   Batch 3,000  of  13,700.    Elapsed: 0:24:03.      Average Loss: 2.0223
2023-04-11 14:00:46,740 - INFO -   Batch 4,000  of  13,700.    Elapsed: 0:32:04.      Average Loss: 1.989
2023-04-11 14:08:48,335 - INFO -   Batch 5,000  of  13,700.    Elapsed: 0:40:06.      Average Loss: 2.01
2023-04-11 14:16:49,033 - INFO -   Batch 6,000  of  13,700.    Elapsed: 0:48:06.      Average Loss: 2.0659
2023-04-11 14:24:50,149 - INFO -   Batch 7,000  of  13,700.    Elapsed: 0:56:07.      Average Loss: 2.0432
2023-04-11 14:32:51,432 - INFO -   Batch 8,000  of  13,700.    Elapsed: 1:04:09.      Average Loss: 1.9941
2023-04-11 14:40:52,708 - INFO -   Batch 9,000  of  13,700.    Elapsed: 1:12:10.      Average Loss: 1.9543
2023-04-11 14:48:53,713 - INFO -   Batch 10,000  of  13,700.    Elapsed: 1:20:11.      Average Loss: 1.9248
2023-04-11 14:56:53,872 - INFO -   Batch 11,000  of  13,700.    Elapsed: 1:28:11.      Average Loss: 1.9216
2023-04-11 15:04:54,444 - INFO -   Batch 12,000  of  13,700.    Elapsed: 1:36:12.      Average Loss: 1.9194
2023-04-11 15:12:55,616 - INFO -   Batch 13,000  of  13,700.    Elapsed: 1:44:13.      Average Loss: 1.8963
2023-04-11 15:18:30,786 - INFO -   Epoch Average Training Loss: 1.90
2023-04-11 15:18:30,786 - INFO -   Training epoch took: 1:49:48
2023-04-11 15:18:30,786 - INFO - Running Validation...
2023-04-11 15:23:15,540 - INFO -   Average Validation Loss: 1.92
2023-04-11 15:23:15,540 - INFO -   Validation took: 0:04:45
2023-04-11 15:23:15,540 - INFO - ======== Epoch 3 / 3 ========
2023-04-11 15:31:17,333 - INFO -   Batch 1,000  of  13,700.    Elapsed: 0:08:02.      Average Loss: 1.7702
2023-04-11 15:39:16,587 - INFO -   Batch 2,000  of  13,700.    Elapsed: 0:16:01.      Average Loss: 1.6564
2023-04-11 15:47:18,455 - INFO -   Batch 3,000  of  13,700.    Elapsed: 0:24:03.      Average Loss: 1.6645
2023-04-11 15:55:19,179 - INFO -   Batch 4,000  of  13,700.    Elapsed: 0:32:04.      Average Loss: 1.6521
2023-04-11 16:03:20,367 - INFO -   Batch 5,000  of  13,700.    Elapsed: 0:40:05.      Average Loss: 1.6431
2023-04-11 16:11:21,448 - INFO -   Batch 6,000  of  13,700.    Elapsed: 0:48:06.      Average Loss: 1.7034
2023-04-11 16:19:23,789 - INFO -   Batch 7,000  of  13,700.    Elapsed: 0:56:08.      Average Loss: 1.6688
2023-04-11 16:27:25,216 - INFO -   Batch 8,000  of  13,700.    Elapsed: 1:04:10.      Average Loss: 1.6141
2023-04-11 16:35:36,572 - INFO -   Batch 9,000  of  13,700.    Elapsed: 1:12:21.      Average Loss: 1.5662
2023-04-11 16:43:50,363 - INFO -   Batch 10,000  of  13,700.    Elapsed: 1:20:35.      Average Loss: 1.5444
2023-04-11 16:51:53,456 - INFO -   Batch 11,000  of  13,700.    Elapsed: 1:28:38.      Average Loss: 1.5442
2023-04-11 16:59:57,766 - INFO -   Batch 12,000  of  13,700.    Elapsed: 1:36:42.      Average Loss: 1.5462
2023-04-11 17:08:02,167 - INFO -   Batch 13,000  of  13,700.    Elapsed: 1:44:47.      Average Loss: 1.5236
2023-04-11 17:13:40,272 - INFO -   Epoch Average Training Loss: 1.52
2023-04-11 17:13:40,273 - INFO -   Training epoch took: 1:50:25
2023-04-11 17:13:40,273 - INFO - Running Validation...
2023-04-11 17:18:24,573 - INFO -   Average Validation Loss: 1.86
2023-04-11 17:18:24,573 - INFO -   Validation took: 0:04:44
2023-04-11 17:18:24,573 - INFO - 
2023-04-11 17:18:24,573 - INFO - Training complete!
2023-04-11 17:18:24,601 - INFO - Pickled loss values
2023-04-11 17:18:26,542 - INFO - Saved model and tokenizer
2023-04-11 17:18:26,542 - INFO - Done!
