First attempt at fine-tuning lead to an increasing training loss after first 3,000 batches:
2023-03-30 22:38:58,849 - INFO - Created train and test datasets
2023-03-30 22:38:58,894 - INFO - Split train data to fine-tune and train datasets
2023-03-30 22:38:58,995 - INFO - Pickled test dataset
2023-03-30 22:38:59,478 - INFO - Pickled train dataset
2023-03-30 22:38:59,478 - INFO - Initializing fine-tune dataset
2023-03-30 22:42:00,082 - INFO - Extracted encodings and labels from chunks and initialized dataset
2023-03-30 22:42:23,112 - INFO - Pickled fine-tune dataset
2023-03-30 22:42:23,157 - INFO - Split fine-tune data to fine-tune and validation datasets
2023-03-30 22:42:26,222 - INFO - Training...
2023-03-30 22:42:26,222 - INFO - ======== Epoch 1 / 3 ========
2023-03-30 23:00:02,938 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:37.      Average Loss: 3.1397
2023-03-30 23:17:42,375 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:16.      Average Loss: 2.8698
2023-03-30 23:35:24,561 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:52:58.      Average Loss: 2.5552
2023-03-30 23:53:05,947 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:40.      Average Loss: 2.7069
2023-03-31 00:10:48,003 - INFO -   Batch 5,000  of  16,327.    Elapsed: 1:28:22.      Average Loss: 2.7847
2023-03-31 00:28:28,781 - INFO -   Batch 6,000  of  16,327.    Elapsed: 1:46:03.      Average Loss: 2.847
2023-03-31 00:46:09,515 - INFO -   Batch 7,000  of  16,327.    Elapsed: 2:03:43.      Average Loss: 2.8846
2023-03-31 01:03:51,271 - INFO -   Batch 8,000  of  16,327.    Elapsed: 2:21:25.      Average Loss: 2.9147
2023-03-31 01:21:33,025 - INFO -   Batch 9,000  of  16,327.    Elapsed: 2:39:07.      Average Loss: 2.9384
2023-03-31 01:39:14,791 - INFO -   Batch 10,000  of  16,327.    Elapsed: 2:56:49.      Average Loss: 2.9564
2023-03-31 01:56:57,379 - INFO -   Batch 11,000  of  16,327.    Elapsed: 3:14:31.      Average Loss: 2.9742
2023-03-31 02:14:41,238 - INFO -   Batch 12,000  of  16,327.    Elapsed: 3:32:15.      Average Loss: 2.9903
2023-03-31 02:32:24,286 - INFO -   Batch 13,000  of  16,327.    Elapsed: 3:49:58.      Average Loss: 3.001
2023-03-31 02:50:06,298 - INFO -   Batch 14,000  of  16,327.    Elapsed: 4:07:40.      Average Loss: 3.0112
2023-03-31 03:07:48,075 - INFO -   Batch 15,000  of  16,327.    Elapsed: 4:25:22.      Average Loss: 3.0202
2023-03-31 03:25:30,634 - INFO -   Batch 16,000  of  16,327.    Elapsed: 4:43:04.      Average Loss: 3.0287
2023-03-31 03:31:16,255 - INFO -   Epoch Average Training Loss: 3.03
2023-03-31 03:31:16,256 - INFO -   Training epoch took: 4:48:50
2023-03-31 03:31:16,256 - INFO - Running Validation...
2023-03-31 03:40:01,889 - INFO -   Average Validation Loss: 3.13
2023-03-31 03:40:01,889 - INFO -   Validation took: 0:08:46
2023-03-31 03:40:01,889 - INFO - ======== Epoch 2 / 3 ========
2023-03-31 03:57:45,343 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:43.      Average Loss: 3.1094
2023-03-31 04:15:28,316 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:26.      Average Loss: 3.1256
2023-03-31 04:33:11,493 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:53:10.      Average Loss: 3.1294
2023-03-31 04:50:56,285 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:54.      Average Loss: 3.1413
2023-03-31 05:08:40,056 - INFO -   Batch 5,000  of  16,327.    Elapsed: 1:28:38.      Average Loss: 3.133
2023-03-31 05:26:23,460 - INFO -   Batch 6,000  of  16,327.    Elapsed: 1:46:22.      Average Loss: 3.1339
2023-03-31 05:44:05,264 - INFO -   Batch 7,000  of  16,327.    Elapsed: 2:04:03.      Average Loss: 3.1343
2023-03-31 06:01:47,354 - INFO -   Batch 8,000  of  16,327.    Elapsed: 2:21:45.      Average Loss: 3.1359
2023-03-31 06:19:30,639 - INFO -   Batch 9,000  of  16,327.    Elapsed: 2:39:29.      Average Loss: 3.1353
2023-03-31 06:37:14,284 - INFO -   Batch 10,000  of  16,327.    Elapsed: 2:57:12.      Average Loss: 3.1347
2023-03-31 06:54:58,072 - INFO -   Batch 11,000  of  16,327.    Elapsed: 3:14:56.      Average Loss: 3.1392
2023-03-31 07:12:44,026 - INFO -   Batch 12,000  of  16,327.    Elapsed: 3:32:42.      Average Loss: 3.1396
2023-03-31 07:30:27,209 - INFO -   Batch 13,000  of  16,327.    Elapsed: 3:50:25.      Average Loss: 3.1391
2023-03-31 07:48:10,708 - INFO -   Batch 14,000  of  16,327.    Elapsed: 4:08:09.      Average Loss: 3.1388
2023-03-31 08:05:54,252 - INFO -   Batch 15,000  of  16,327.    Elapsed: 4:25:52.      Average Loss: 3.1397
2023-03-31 08:23:38,145 - INFO -   Batch 16,000  of  16,327.    Elapsed: 4:43:36.      Average Loss: 3.1407
2023-03-31 08:29:24,450 - INFO -   Epoch Average Training Loss: 3.14
2023-03-31 08:29:24,450 - INFO -   Training epoch took: 4:49:23
2023-03-31 08:29:24,450 - INFO - Running Validation...
2023-03-31 08:38:09,702 - INFO -   Average Validation Loss: 3.13
2023-03-31 08:38:09,702 - INFO -   Validation took: 0:08:45
2023-03-31 08:38:09,702 - INFO - ======== Epoch 3 / 3 ========
2023-03-31 08:55:53,381 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:44.      Average Loss: 3.1086
2023-03-31 09:13:36,201 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:26.      Average Loss: 3.134
2023-03-31 09:31:18,754 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:53:09.      Average Loss: 3.1368
2023-03-31 09:49:03,398 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:54.      Average Loss: 3.1419
2023-03-31 10:49:29,345 - INFO - Created train and test datasets
2023-03-31 10:49:29,390 - INFO - Split train data to fine-tune and train datasets
2023-03-31 10:49:29,487 - INFO - Pickled test dataset
2023-03-31 10:49:29,909 - INFO - Pickled train dataset

Second attempt after cutting the learning rate in half:
2023-03-31 16:03:24,448 - INFO - Created train and test datasets
2023-03-31 16:03:24,492 - INFO - Split train data to fine-tune and train datasets
2023-03-31 16:03:24,597 - INFO - Pickled test dataset
2023-03-31 16:03:25,042 - INFO - Pickled train dataset
2023-03-31 16:03:25,042 - INFO - Initializing fine-tune dataset
2023-03-31 16:06:26,921 - INFO - Extracted encodings and labels from chunks and initialized dataset
2023-03-31 16:06:49,666 - INFO - Pickled fine-tune dataset
2023-03-31 16:06:49,715 - INFO - Split fine-tune data to fine-tune and validation datasets
2023-03-31 16:06:53,405 - INFO - Training...
2023-03-31 16:06:53,405 - INFO - ======== Epoch 1 / 3 ========
2023-03-31 16:24:33,205 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:40.      Average Loss: 3.1429
2023-03-31 16:42:14,491 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:21.      Average Loss: 2.9307
2023-03-31 16:59:57,644 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:53:04.      Average Loss: 2.7072
2023-03-31 17:17:39,401 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:46.      Average Loss: 2.498
2023-03-31 17:35:21,129 - INFO -   Batch 5,000  of  16,327.    Elapsed: 1:28:28.      Average Loss: 2.3616
2023-03-31 17:53:04,195 - INFO -   Batch 6,000  of  16,327.    Elapsed: 1:46:11.      Average Loss: 2.291
2023-03-31 18:10:46,520 - INFO -   Batch 7,000  of  16,327.    Elapsed: 2:03:53.      Average Loss: 2.2171
2023-03-31 18:28:28,049 - INFO -   Batch 8,000  of  16,327.    Elapsed: 2:21:35.      Average Loss: 2.2247
2023-03-31 18:46:11,137 - INFO -   Batch 9,000  of  16,327.    Elapsed: 2:39:18.      Average Loss: 2.1136
2023-03-31 19:03:53,502 - INFO -   Batch 10,000  of  16,327.    Elapsed: 2:57:00.      Average Loss: 2.0571
2023-03-31 19:21:35,900 - INFO -   Batch 11,000  of  16,327.    Elapsed: 3:14:42.      Average Loss: 1.9722
2023-03-31 19:39:19,925 - INFO -   Batch 12,000  of  16,327.    Elapsed: 3:32:27.      Average Loss: 1.9161
2023-03-31 19:57:01,932 - INFO -   Batch 13,000  of  16,327.    Elapsed: 3:50:09.      Average Loss: 1.8498
2023-03-31 20:14:45,384 - INFO -   Batch 14,000  of  16,327.    Elapsed: 4:07:52.      Average Loss: 1.8406
2023-03-31 20:32:28,036 - INFO -   Batch 15,000  of  16,327.    Elapsed: 4:25:35.      Average Loss: 1.8353
2023-03-31 20:50:10,734 - INFO -   Batch 16,000  of  16,327.    Elapsed: 4:43:17.      Average Loss: 1.8227
2023-03-31 20:55:56,789 - INFO -   Epoch Average Training Loss: 1.83
2023-03-31 20:55:56,789 - INFO -   Training epoch took: 4:49:03
2023-03-31 20:55:56,789 - INFO - Running Validation...
2023-03-31 21:04:42,090 - INFO -   Average Validation Loss: 1.54
2023-03-31 21:04:42,090 - INFO -   Validation took: 0:08:45
2023-03-31 21:04:42,090 - INFO - ======== Epoch 2 / 3 ========
2023-03-31 21:22:25,662 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:44.      Average Loss: 2.1942
2023-03-31 21:40:07,826 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:26.      Average Loss: 1.8827
2023-03-31 21:57:49,740 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:53:08.      Average Loss: 1.8089
2023-03-31 22:15:35,466 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:53.      Average Loss: 1.6996
2023-03-31 22:33:18,439 - INFO -   Batch 5,000  of  16,327.    Elapsed: 1:28:36.      Average Loss: 1.616
2023-03-31 22:51:02,215 - INFO -   Batch 6,000  of  16,327.    Elapsed: 1:46:20.      Average Loss: 1.612
2023-03-31 23:08:45,712 - INFO -   Batch 7,000  of  16,327.    Elapsed: 2:04:04.      Average Loss: 1.5654
2023-03-31 23:26:29,553 - INFO -   Batch 8,000  of  16,327.    Elapsed: 2:21:47.      Average Loss: 1.6211
2023-03-31 23:44:12,057 - INFO -   Batch 9,000  of  16,327.    Elapsed: 2:39:30.      Average Loss: 1.5383
2023-04-01 00:01:53,678 - INFO -   Batch 10,000  of  16,327.    Elapsed: 2:57:12.      Average Loss: 1.5144
2023-04-01 00:19:36,669 - INFO -   Batch 11,000  of  16,327.    Elapsed: 3:14:55.      Average Loss: 1.4647
2023-04-01 00:37:20,938 - INFO -   Batch 12,000  of  16,327.    Elapsed: 3:32:39.      Average Loss: 1.4397
2023-04-01 00:55:02,830 - INFO -   Batch 13,000  of  16,327.    Elapsed: 3:50:21.      Average Loss: 1.3994
2023-04-01 01:12:44,563 - INFO -   Batch 14,000  of  16,327.    Elapsed: 4:08:02.      Average Loss: 1.4137
2023-04-01 01:30:26,133 - INFO -   Batch 15,000  of  16,327.    Elapsed: 4:25:44.      Average Loss: 1.4078
2023-04-01 01:48:07,528 - INFO -   Batch 16,000  of  16,327.    Elapsed: 4:43:25.      Average Loss: 1.3972
2023-04-01 01:53:53,407 - INFO -   Epoch Average Training Loss: 1.42
2023-04-01 01:53:53,407 - INFO -   Training epoch took: 4:49:11
2023-04-01 01:53:53,407 - INFO - Running Validation...
2023-04-01 02:02:37,545 - INFO -   Average Validation Loss: 1.45
2023-04-01 02:02:37,545 - INFO -   Validation took: 0:08:44
2023-04-01 02:02:37,545 - INFO - ======== Epoch 3 / 3 ========
2023-04-01 02:20:20,087 - INFO -   Batch 1,000  of  16,327.    Elapsed: 0:17:43.      Average Loss: 1.8455
2023-04-01 02:38:03,027 - INFO -   Batch 2,000  of  16,327.    Elapsed: 0:35:25.      Average Loss: 1.4662
2023-04-01 02:55:44,034 - INFO -   Batch 3,000  of  16,327.    Elapsed: 0:53:06.      Average Loss: 1.4298
2023-04-01 03:13:28,319 - INFO -   Batch 4,000  of  16,327.    Elapsed: 1:10:51.      Average Loss: 1.3485
2023-04-01 03:31:11,640 - INFO -   Batch 5,000  of  16,327.    Elapsed: 1:28:34.      Average Loss: 1.2732
2023-04-01 03:48:54,769 - INFO -   Batch 6,000  of  16,327.    Elapsed: 1:46:17.      Average Loss: 1.27
2023-04-01 04:06:38,020 - INFO -   Batch 7,000  of  16,327.    Elapsed: 2:04:00.      Average Loss: 1.2193
2023-04-01 04:24:19,875 - INFO -   Batch 8,000  of  16,327.    Elapsed: 2:21:42.      Average Loss: 1.3005
2023-04-01 04:42:02,707 - INFO -   Batch 9,000  of  16,327.    Elapsed: 2:39:25.      Average Loss: 1.2441
2023-04-01 04:59:44,733 - INFO -   Batch 10,000  of  16,327.    Elapsed: 2:57:07.      Average Loss: 1.2136
2023-04-01 05:17:27,111 - INFO -   Batch 11,000  of  16,327.    Elapsed: 3:14:50.      Average Loss: 1.1839
2023-04-01 05:35:10,567 - INFO -   Batch 12,000  of  16,327.    Elapsed: 3:32:33.      Average Loss: 1.1628
2023-04-01 05:52:54,755 - INFO -   Batch 13,000  of  16,327.    Elapsed: 3:50:17.      Average Loss: 1.1309
2023-04-01 06:10:38,438 - INFO -   Batch 14,000  of  16,327.    Elapsed: 4:08:01.      Average Loss: 1.1482
2023-04-01 06:28:20,817 - INFO -   Batch 15,000  of  16,327.    Elapsed: 4:25:43.      Average Loss: 1.1422
2023-04-01 06:46:03,771 - INFO -   Batch 16,000  of  16,327.    Elapsed: 4:43:26.      Average Loss: 1.1225
2023-04-01 06:51:49,892 - INFO -   Epoch Average Training Loss: 1.14
2023-04-01 06:51:49,892 - INFO -   Training epoch took: 4:49:12
2023-04-01 06:51:49,892 - INFO - Running Validation...
2023-04-01 07:00:36,347 - INFO -   Average Validation Loss: 1.44
2023-04-01 07:00:36,348 - INFO -   Validation took: 0:08:46
2023-04-01 07:00:36,348 - INFO - 
2023-04-01 07:00:36,348 - INFO - Training complete!
2023-04-01 07:00:36,348 - INFO - Pickled loss values
2023-04-01 07:00:36,932 - INFO - Saved model and tokenizer
2023-04-01 07:00:36,932 - INFO - Done!
