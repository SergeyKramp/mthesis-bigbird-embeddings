{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.dataprocessor import DataProcessor\n",
    "from feature_extractors.normal_feature_extractor import NormalFeatureExtractor\n",
    "from feature_extractors.transformer_feature_extractor import TransformerFeatureExtractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `non-europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_X_normal_chunks.pkl', 'rb')).to_numpy()\n",
    "\n",
    "X_bigbird_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_X_bigbird_chunks.pkl', 'rb'))\n",
    "X_bigbird_fine_tuned_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_X_bigbird_fine_tuned_chunks.pkl', 'rb'))\n",
    "\n",
    "y_non_europe = pickle.load(open('pickles/pickled_datasets/seed_42/out_of_domain_y_chunks.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal_non_europe_train = X_normal_non_europe[:int(len(X_normal_non_europe)*0.8)]\n",
    "X_normal_non_europe_test = X_normal_non_europe[int(len(X_normal_non_europe)*0.8):]\n",
    "\n",
    "X_bigbird_non_europe_train = X_bigbird_non_europe[:int(len(X_bigbird_non_europe)*0.8)]\n",
    "X_bigbird_non_europe_test = X_bigbird_non_europe[int(len(X_bigbird_non_europe)*0.8):]\n",
    "\n",
    "X_bigbird_fine_tuned_non_europe_train = X_bigbird_fine_tuned_non_europe[:int(len(X_bigbird_fine_tuned_non_europe)*0.8)]\n",
    "X_bigbird_fine_tuned_non_europe_test = X_bigbird_fine_tuned_non_europe[int(len(X_bigbird_fine_tuned_non_europe)*0.8):]\n",
    "\n",
    "y_non_europe_train = y_non_europe[:int(len(y_non_europe)*0.8)]\n",
    "y_non_europe_test = y_non_europe[int(len(y_non_europe)*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifiers on `non_europe` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23672/410217484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf_normal_non_europe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normal_non_europe_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_non_europe_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf_bigbird_non_europe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bigbird_non_europe_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_non_europe_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_bigbird_fine_tuned_non_europe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bigbird_fine_tuned_non_europe_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_non_europe_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    814\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_normal_non_europe = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_normal_non_europe_train, y_non_europe_train)\n",
    "clf_bigbird_non_europe = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_bigbird_non_europe_train, y_non_europe_train)\n",
    "clf_bigbird_fine_tuned_non_europe = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_bigbird_fine_tuned_non_europe_train, y_non_europe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/new_clf_normal_non_europe_seed_42_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_normal_non_europe, f)\n",
    "    \n",
    "with open('pickles/new_clf_bigbird_non_europe_seed_42_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_bigbird_non_europe, f)\n",
    "    \n",
    "with open('pickles/new_clf_bigbird_fine_tuned_non_europe_seed_42_chunks.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_bigbird_fine_tuned_non_europe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/new_clf_normal_non_europe_seed_42_chunks.pkl', 'rb') as f:\n",
    "    clf_normal_non_europe = pickle.load(f)\n",
    "\n",
    "with open('pickles/new_clf_bigbird_non_europe_seed_42_chunks.pkl', 'rb') as f:\n",
    "    clf_bigbird_non_europe = pickle.load(f)\n",
    "    \n",
    "with open('pickles/new_clf_bigbird_fine_tuned_non_europe_seed_42_chunks.pkl', 'rb') as f:\n",
    "    clf_bigbird_fine_tuned_non_europe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `toefl` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Language</th>\n",
       "      <th>Score Level</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348.txt</td>\n",
       "      <td>P1</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666.txt</td>\n",
       "      <td>P2</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>733.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>976.txt</td>\n",
       "      <td>P2</td>\n",
       "      <td>ARA</td>\n",
       "      <td>low</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename Prompt Language Score Level Source\n",
       "0  278.txt     P6      DEU      medium  train\n",
       "1  348.txt     P1      TUR        high  train\n",
       "2  666.txt     P2      ZHO      medium  train\n",
       "3  733.txt     P6      TEL      medium  train\n",
       "4  976.txt     P2      ARA         low  train"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toefl = pd.read_csv('./data/toefl/ETS_Corpus_of_Non-Native_Written_English/data/text/index.csv')\n",
    "\n",
    "df_toefl_train = pd.read_csv('./data/toefl/ETS_Corpus_of_Non-Native_Written_English/data/text/index-training.csv', header=None, names=['Filename', 'Prompt', 'Language', 'Score Level'])\n",
    "df_toefl_train['Source'] = ['train'] * len(df_toefl_train)\n",
    "\n",
    "df_toefl_test = pd.read_csv('./data/toefl/ETS_Corpus_of_Non-Native_Written_English/data/text/index-test.csv', header=None, names=['Filename', 'Prompt', 'Score Level'])\n",
    "df_toefl_test = df_toefl[df_toefl['Filename'].isin(df_toefl_test['Filename'])]\n",
    "df_toefl_test['Source'] = ['test'] * len(df_toefl_test)\n",
    "\n",
    "df_toefl = pd.merge(df_toefl_train, df_toefl_test, how='outer')\n",
    "df_toefl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DEU', 'TUR', 'ZHO', 'TEL', 'ARA', 'SPA', 'HIN', 'JPN', 'KOR',\n",
       "       'FRA', 'ITA'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toefl['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Language</th>\n",
       "      <th>Score Level</th>\n",
       "      <th>Source</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348.txt</td>\n",
       "      <td>P1</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1612.txt</td>\n",
       "      <td>P6</td>\n",
       "      <td>SPA</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>In my opinion, travel in group with a tour gui...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024.txt</td>\n",
       "      <td>P3</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>train</td>\n",
       "      <td>I thing the statement ''Young people nowadays ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2664.txt</td>\n",
       "      <td>P2</td>\n",
       "      <td>DEU</td>\n",
       "      <td>high</td>\n",
       "      <td>train</td>\n",
       "      <td>Whether or not young people enjoy life more th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Filename Prompt Language Score Level Source  \\\n",
       "0   278.txt     P6      DEU      medium  train   \n",
       "1   348.txt     P1      TUR        high  train   \n",
       "5  1612.txt     P6      SPA      medium  train   \n",
       "6  2024.txt     P3      DEU      medium  train   \n",
       "7  2664.txt     P2      DEU        high  train   \n",
       "\n",
       "                                                Text  Label  \n",
       "0  IThe importance and popularity of travelling i...      1  \n",
       "1  It is an important decision, how to plan your ...     22  \n",
       "5  In my opinion, travel in group with a tour gui...     20  \n",
       "6  I thing the statement ''Young people nowadays ...      1  \n",
       "7  Whether or not young people enjoy life more th...      1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file_contents(filename):\n",
    "    try:\n",
    "        with open(f'./data/toefl/ETS_Corpus_of_Non-Native_Written_English/data/text/responses/original/{filename}', 'r') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    \n",
    "def assign_label(iso_lang):\n",
    "    language2label = {\n",
    "        'JPN': 0,\n",
    "        'ARA': 0,\n",
    "        'KOR': 0,\n",
    "        'HIN': 0,\n",
    "        'TEL': 0,\n",
    "        'ZHO': 0,\n",
    "        'DEU': 1,\n",
    "        'FRA': 7,\n",
    "        'ITA': 10,\n",
    "        'SPA': 20,\n",
    "        'TUR': 22\n",
    "    }\n",
    "    return language2label[iso_lang]\n",
    "\n",
    "df_toefl['Text'] = df_toefl['Filename'].apply(read_file_contents)\n",
    "df_toefl['Label'] = df_toefl['Language'].apply(assign_label)\n",
    "df_toefl = df_toefl[df_toefl['Label'] != 0]\n",
    "df_toefl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322.124"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toefl.Text.apply(lambda x: len(x.split(' '))).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features from `toefl` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "normalizer.cc(50) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks were not used when initializing BigBirdModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word ngram features...\n",
      "Creating char ngram features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating edit distance: 100%|███████████| 5000/5000 [00:11<00:00, 422.58it/s]\n",
      "Extracting Substitution Features: 100%|████| 5000/5000 [00:15<00:00, 319.34it/s]\n",
      "Extracting Function Word Features: 5000it [00:07, 652.80it/s]\n",
      "Extracting POS Features: 5000it [01:09, 72.28it/s]\n",
      "Extracting Average Sentence Length: 100%|█| 5000/5000 [00:00<00:00, 18608.85it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Grammar Features: 100%|██████████| 5000/5000 [07:58<00:00, 10.44it/s]\n",
      "Extracting features: 100%|██████████████████| 5000/5000 [11:02<00:00,  7.54it/s]\n",
      "Extracting features: 100%|██████████████████| 5000/5000 [11:24<00:00,  7.31it/s]\n"
     ]
    }
   ],
   "source": [
    "normal_feature_extractor = pickle.load(open('pickles/normal_feature_extractor_seed_42_chunks.pkl', 'rb'))\n",
    "big_bird_non_europe_feature_extractor = TransformerFeatureExtractor('google/bigbird-roberta-base', 2048)\n",
    "big_bird_fine_tuned_non_europe_feature_extractor = TransformerFeatureExtractor('fine_tuned_models/out_of_domain_bigbird_roberta_base_clean_chunks', 2048)\n",
    "\n",
    "def insert_grammar_features(all_features: np.array, grammar_features: np.array) -> np.array:\n",
    "    return np.concatenate((all_features[:, :2300], grammar_features, all_features[:, 2300:]), axis=1)\n",
    "\n",
    "X_normal_toefl = normal_feature_extractor.transform(df_toefl.Text.to_list(), grammar_mistakes=False).to_numpy()\n",
    "grammar_features = normal_feature_extractor.get_grammar_features(df_toefl.Text.to_list())\n",
    "\n",
    "X_normal_toefl = insert_grammar_features(X_normal_toefl, grammar_features)\n",
    "\n",
    "X_bigbird = big_bird_non_europe_feature_extractor.transform(df_toefl.Text.to_list())\n",
    "X_bigbird_fine = big_bird_fine_tuned_non_europe_feature_extractor.transform(df_toefl.Text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pickles/new_normal_toefl_seed_42_chunks.pkl', 'wb') as f:\n",
    "#     pickle.dump(X_normal_toefl, f)\n",
    "    \n",
    "# with open('pickles/new_bigbird_toefl_seed_42_chunks.pkl', 'wb') as f:\n",
    "#     pickle.dump(X_bigbird, f)\n",
    "    \n",
    "# with open('pickles/new_bigbird_fine_tuned_toefl_seed_42_chunks.pkl', 'wb') as f:\n",
    "#     pickle.dump(X_bigbird_fine, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/new_normal_toefl_seed_42_chunks.pkl', 'rb') as f:\n",
    "    X_normal_toefl = pickle.load(f)\n",
    "    \n",
    "with open('pickles/new_bigbird_toefl_seed_42_chunks.pkl', 'rb') as f:\n",
    "    X_bigbird_toefl = pickle.load(f)\n",
    "    \n",
    "with open('pickles/new_bigbird_fine_tuned_toefl_seed_42_chunks.pkl', 'rb') as f:\n",
    "    X_bigbird_fine_toefl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "toefl_train_ix = df_toefl.loc[df_toefl['Source'] == 'train'].index.to_list()\n",
    "toefl_test_ix = df_toefl.loc[df_toefl['Source'] == 'test'].index.to_list()\n",
    "\n",
    "X_normal_toefl_train = X_normal_non_europe[toefl_train_ix]\n",
    "X_normal_toefl_test = X_normal_non_europe[toefl_test_ix]\n",
    "\n",
    "X_bigbird_toefl_train = X_bigbird_non_europe[toefl_train_ix]\n",
    "X_bigbird_toefl_test = X_bigbird_non_europe[toefl_test_ix]\n",
    "\n",
    "X_bigbird_fine_tuned_toefl_train = X_bigbird_fine_tuned_non_europe[toefl_train_ix]\n",
    "X_bigbird_fine_tuned_toefl_test = X_bigbird_fine_tuned_non_europe[toefl_test_ix]\n",
    "\n",
    "y_toefl_train = df_toefl[df_toefl['Source'] == 'train']['Label'].to_list()\n",
    "y_toefl_test = df_toefl[df_toefl['Source'] == 'test']['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F =   54889.456320398887     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        17687     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.32527D+04    |proj g|=  4.15286D+03\n",
      "\n",
      "At iterate   50    f=  2.77199D+04    |proj g|=  1.43165D+02\n",
      "\n",
      "At iterate  100    f=  2.50174D+04    |proj g|=  4.17377D+02\n",
      "\n",
      "At iterate  150    f=  2.42141D+04    |proj g|=  2.79269D+02\n",
      "\n",
      "At iterate  200    f=  2.39562D+04    |proj g|=  6.26058D+01\n",
      "\n",
      "At iterate  250    f=  2.38600D+04    |proj g|=  1.72157D+01\n",
      "\n",
      "At iterate  300    f=  2.38233D+04    |proj g|=  6.10771D+01\n",
      "\n",
      "At iterate  350    f=  2.38076D+04    |proj g|=  9.85891D+00\n",
      "\n",
      "At iterate  400    f=  2.38009D+04    |proj g|=  1.15009D+01\n",
      "\n",
      "At iterate  450    f=  2.37973D+04    |proj g|=  6.37316D+00\n",
      "\n",
      "At iterate  500    f=  2.37951D+04    |proj g|=  6.11802D+00\n",
      "\n",
      "At iterate  550    f=  2.37935D+04    |proj g|=  2.23273D+00\n",
      "\n",
      "At iterate  600    f=  2.37921D+04    |proj g|=  4.84983D+00\n",
      "\n",
      "At iterate  650    f=  2.37909D+04    |proj g|=  3.29043D+00\n",
      "\n",
      "At iterate  700    f=  2.37897D+04    |proj g|=  6.68393D+00\n",
      "\n",
      "At iterate  750    f=  2.37885D+04    |proj g|=  3.67072D+00\n",
      "\n",
      "At iterate  800    f=  2.37876D+04    |proj g|=  3.00927D+00\n",
      "\n",
      "At iterate  850    f=  2.37869D+04    |proj g|=  1.09195D+01\n",
      "\n",
      "At iterate  900    f=  2.37864D+04    |proj g|=  9.24641D-01\n",
      "\n",
      "At iterate  950    f=  2.37861D+04    |proj g|=  1.60701D+00\n",
      "\n",
      "At iterate 1000    f=  2.37860D+04    |proj g|=  3.11536D+00\n",
      "\n",
      "At iterate 1050    f=  2.37859D+04    |proj g|=  3.22376D-01\n",
      "\n",
      "At iterate 1100    f=  2.37858D+04    |proj g|=  1.97357D+00\n",
      "\n",
      "At iterate 1150    f=  2.37858D+04    |proj g|=  3.51314D-01\n",
      "\n",
      "At iterate 1200    f=  2.37858D+04    |proj g|=  5.01552D-01\n",
      "\n",
      "At iterate 1250    f=  2.37858D+04    |proj g|=  7.33943D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "17687   1262   1298      1     0     0   9.251D-01   2.379D+04\n",
      "  F =   23785.796334385046     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        25935     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.24247D+03    |proj g|=  2.90740D+03\n",
      "\n",
      "At iterate   50    f=  6.04725D+03    |proj g|=  1.16533D+04\n",
      "\n",
      "At iterate  100    f=  5.24245D+03    |proj g|=  3.51835D+03\n",
      "\n",
      "At iterate  150    f=  4.65040D+03    |proj g|=  1.26875D+04\n",
      "\n",
      "At iterate  200    f=  4.13042D+03    |proj g|=  2.80949D+03\n",
      "\n",
      "At iterate  250    f=  3.63125D+03    |proj g|=  5.08033D+03\n",
      "\n",
      "At iterate  300    f=  3.17999D+03    |proj g|=  4.22714D+03\n",
      "\n",
      "At iterate  350    f=  2.71417D+03    |proj g|=  2.66216D+03\n",
      "\n",
      "At iterate  400    f=  2.28521D+03    |proj g|=  1.80776D+03\n",
      "\n",
      "At iterate  450    f=  1.89537D+03    |proj g|=  1.56734D+03\n",
      "\n",
      "At iterate  500    f=  1.53055D+03    |proj g|=  1.97606D+03\n",
      "\n",
      "At iterate  550    f=  1.18587D+03    |proj g|=  1.47447D+03\n",
      "\n",
      "At iterate  600    f=  8.90951D+02    |proj g|=  8.60019D+02\n",
      "\n",
      "At iterate  650    f=  6.85980D+02    |proj g|=  2.13082D+03\n",
      "\n",
      "At iterate  700    f=  5.88264D+02    |proj g|=  5.60028D+02\n",
      "\n",
      "At iterate  750    f=  5.32002D+02    |proj g|=  7.57241D+02\n",
      "\n",
      "At iterate  800    f=  4.83863D+02    |proj g|=  4.94811D+02\n",
      "\n",
      "At iterate  850    f=  4.42076D+02    |proj g|=  2.73209D+02\n",
      "\n",
      "At iterate  900    f=  4.14002D+02    |proj g|=  2.70903D+02\n",
      "\n",
      "At iterate  950    f=  3.92889D+02    |proj g|=  3.32013D+02\n",
      "\n",
      "At iterate 1000    f=  3.73845D+02    |proj g|=  9.34951D+01\n",
      "\n",
      "At iterate 1050    f=  3.57485D+02    |proj g|=  3.79841D+02\n",
      "\n",
      "At iterate 1100    f=  3.46665D+02    |proj g|=  2.85561D+02\n",
      "\n",
      "At iterate 1150    f=  3.38683D+02    |proj g|=  7.86169D+01\n",
      "\n",
      "At iterate 1200    f=  3.32097D+02    |proj g|=  9.47310D+01\n",
      "\n",
      "At iterate 1250    f=  3.24595D+02    |proj g|=  2.94080D+02\n",
      "\n",
      "At iterate 1300    f=  3.17476D+02    |proj g|=  1.26642D+02\n",
      "\n",
      "At iterate 1350    f=  3.13329D+02    |proj g|=  6.95869D+01\n",
      "\n",
      "At iterate 1400    f=  3.08074D+02    |proj g|=  1.83427D+02\n",
      "\n",
      "At iterate 1450    f=  3.02852D+02    |proj g|=  1.46999D+02\n",
      "\n",
      "At iterate 1500    f=  2.97266D+02    |proj g|=  1.46249D+02\n",
      "\n",
      "At iterate 1550    f=  2.93140D+02    |proj g|=  5.69567D+01\n",
      "\n",
      "At iterate 1600    f=  2.88761D+02    |proj g|=  1.33039D+02\n",
      "\n",
      "At iterate 1650    f=  2.85499D+02    |proj g|=  8.47232D+01\n",
      "\n",
      "At iterate 1700    f=  2.82404D+02    |proj g|=  1.46873D+02\n",
      "\n",
      "At iterate 1750    f=  2.79038D+02    |proj g|=  4.81050D+01\n",
      "\n",
      "At iterate 1800    f=  2.74988D+02    |proj g|=  1.35394D+02\n",
      "\n",
      "At iterate 1850    f=  2.71260D+02    |proj g|=  1.17494D+02\n",
      "\n",
      "At iterate 1900    f=  2.67222D+02    |proj g|=  1.91639D+02\n",
      "\n",
      "At iterate 1950    f=  2.63098D+02    |proj g|=  9.78025D+01\n",
      "\n",
      "At iterate 2000    f=  2.59633D+02    |proj g|=  4.97682D+01\n",
      "\n",
      "At iterate 2050    f=  2.56570D+02    |proj g|=  6.96716D+01\n",
      "\n",
      "At iterate 2100    f=  2.53957D+02    |proj g|=  8.19041D+01\n",
      "\n",
      "At iterate 2150    f=  2.51934D+02    |proj g|=  6.12320D+01\n",
      "\n",
      "At iterate 2200    f=  2.49590D+02    |proj g|=  5.38438D+01\n",
      "\n",
      "At iterate 2250    f=  2.47999D+02    |proj g|=  1.25346D+02\n",
      "\n",
      "At iterate 2300    f=  2.46370D+02    |proj g|=  2.58244D+01\n",
      "\n",
      "At iterate 2350    f=  2.45001D+02    |proj g|=  4.32415D+01\n",
      "\n",
      "At iterate 2400    f=  2.43788D+02    |proj g|=  7.17255D+01\n",
      "\n",
      "At iterate 2450    f=  2.42853D+02    |proj g|=  5.53425D+01\n",
      "\n",
      "At iterate 2500    f=  2.41933D+02    |proj g|=  2.09008D+01\n",
      "\n",
      "At iterate 2550    f=  2.41131D+02    |proj g|=  2.63797D+01\n",
      "\n",
      "At iterate 2600    f=  2.40383D+02    |proj g|=  3.51641D+01\n",
      "\n",
      "At iterate 2650    f=  2.39690D+02    |proj g|=  4.84485D+01\n",
      "\n",
      "At iterate 2700    f=  2.39028D+02    |proj g|=  4.21794D+01\n",
      "\n",
      "At iterate 2750    f=  2.38491D+02    |proj g|=  1.73962D+01\n",
      "\n",
      "At iterate 2800    f=  2.38038D+02    |proj g|=  3.42707D+01\n",
      "\n",
      "At iterate 2850    f=  2.37620D+02    |proj g|=  4.62699D+01\n",
      "\n",
      "At iterate 2900    f=  2.37221D+02    |proj g|=  2.50680D+01\n",
      "\n",
      "At iterate 2950    f=  2.36796D+02    |proj g|=  4.23257D+01\n",
      "\n",
      "At iterate 3000    f=  2.36439D+02    |proj g|=  4.36795D+01\n",
      "\n",
      "At iterate 3050    f=  2.36152D+02    |proj g|=  3.50452D+01\n",
      "\n",
      "At iterate 3100    f=  2.35926D+02    |proj g|=  1.47584D+01\n",
      "\n",
      "At iterate 3150    f=  2.35719D+02    |proj g|=  3.53840D+01\n",
      "\n",
      "At iterate 3200    f=  2.35552D+02    |proj g|=  2.33624D+01\n",
      "\n",
      "At iterate 3250    f=  2.35425D+02    |proj g|=  3.42008D+01\n",
      "\n",
      "At iterate 3300    f=  2.35266D+02    |proj g|=  4.10609D+01\n",
      "\n",
      "At iterate 3350    f=  2.35113D+02    |proj g|=  3.98629D+01\n",
      "\n",
      "At iterate 3400    f=  2.34972D+02    |proj g|=  1.18312D+01\n",
      "\n",
      "At iterate 3450    f=  2.34838D+02    |proj g|=  3.84655D+01\n",
      "\n",
      "At iterate 3500    f=  2.34711D+02    |proj g|=  1.17014D+01\n",
      "\n",
      "At iterate 3550    f=  2.34579D+02    |proj g|=  1.03455D+01\n",
      "\n",
      "At iterate 3600    f=  2.34476D+02    |proj g|=  1.38278D+01\n",
      "\n",
      "At iterate 3650    f=  2.34405D+02    |proj g|=  8.47990D+00\n",
      "\n",
      "At iterate 3700    f=  2.34368D+02    |proj g|=  1.67035D+01\n",
      "\n",
      "At iterate 3750    f=  2.34318D+02    |proj g|=  7.75498D+00\n",
      "\n",
      "At iterate 3800    f=  2.34281D+02    |proj g|=  1.26895D+01\n",
      "\n",
      "At iterate 3850    f=  2.34246D+02    |proj g|=  7.52130D+00\n",
      "\n",
      "At iterate 3900    f=  2.34207D+02    |proj g|=  5.37315D+00\n",
      "\n",
      "At iterate 3950    f=  2.34160D+02    |proj g|=  1.04471D+01\n",
      "\n",
      "At iterate 4000    f=  2.34116D+02    |proj g|=  1.02753D+01\n",
      "\n",
      "At iterate 4050    f=  2.34071D+02    |proj g|=  7.82176D+00\n",
      "\n",
      "At iterate 4100    f=  2.34028D+02    |proj g|=  1.52847D+01\n",
      "\n",
      "At iterate 4150    f=  2.33990D+02    |proj g|=  6.03958D+00\n",
      "\n",
      "At iterate 4200    f=  2.33942D+02    |proj g|=  6.37972D+00\n",
      "\n",
      "At iterate 4250    f=  2.33865D+02    |proj g|=  1.78642D+01\n",
      "\n",
      "At iterate 4300    f=  2.33789D+02    |proj g|=  1.18726D+01\n",
      "\n",
      "At iterate 4350    f=  2.33697D+02    |proj g|=  2.69120D+01\n",
      "\n",
      "At iterate 4400    f=  2.33618D+02    |proj g|=  1.48834D+01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf_normal_toefl = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_normal_toefl_train, y_toefl_train)\n",
    "clf_bigbird_toefl = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_bigbird_toefl_train, y_toefl_train)\n",
    "clf_bigbird_fine_tuned_toefl = LogisticRegression(random_state=seed, max_iter=5000, verbose=1).fit(X_bigbird_fine_tuned_toefl_train, y_toefl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.461807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigbird</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.492335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bigbird_fine_tuned</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.644567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigbird</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bigbird_fine_tuned</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>normal</td>\n",
       "      <td>toefl</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.042765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bigbird</td>\n",
       "      <td>toefl</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.045186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bigbird_fine_tuned</td>\n",
       "      <td>toefl</td>\n",
       "      <td>non_europe</td>\n",
       "      <td>0.039672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>toefl</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bigbird</td>\n",
       "      <td>toefl</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bigbird_fine_tuned</td>\n",
       "      <td>toefl</td>\n",
       "      <td>toefl</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model       train        test  accuracy\n",
       "0               normal  non_europe  non_europe  0.461807\n",
       "1              bigbird  non_europe  non_europe  0.492335\n",
       "2   bigbird_fine_tuned  non_europe  non_europe  0.644567\n",
       "3               normal  non_europe       toefl  0.054000\n",
       "4              bigbird  non_europe       toefl  0.044000\n",
       "5   bigbird_fine_tuned  non_europe       toefl  0.052000\n",
       "6               normal       toefl  non_europe  0.042765\n",
       "7              bigbird       toefl  non_europe  0.045186\n",
       "8   bigbird_fine_tuned       toefl  non_europe  0.039672\n",
       "9               normal       toefl       toefl  0.172000\n",
       "10             bigbird       toefl       toefl  0.190000\n",
       "11  bigbird_fine_tuned       toefl       toefl  0.170000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame([], columns=['model', 'train', 'test', 'accuracy'])\n",
    "i = 0\n",
    "for outer_data in ['non_europe', 'toefl']:\n",
    "    for inner_data in ['non_europe', 'toefl']:\n",
    "        for clf in ['normal', 'bigbird', 'bigbird_fine_tuned']:\n",
    "            eval(f\"exec('pred_{clf}_{outer_data}_{inner_data} = clf_{clf}_{outer_data}.predict(X_{clf}_{inner_data}_test)')\")\n",
    "            if inner_data == 'non_europe':\n",
    "                y_true = y_non_europe_test\n",
    "            else:\n",
    "                y_true = y_toefl_test\n",
    "            acc = accuracy_score(y_true=y_true, y_pred=eval(f\"pred_{clf}_{outer_data}_{inner_data}\"))\n",
    "#             print(f\"Accuracy: {clf} \\t\" + (\"\\t\" if 'fine' not in clf else \"\") + \n",
    "#                   f\"({outer_data}) -> ({inner_data}) \\t\" + \n",
    "#                   (\"\\t\" if inner_data == outer_data and inner_data == \"toefl\" else \"\") + \n",
    "#                   f\" = {round(acc, 3):.3f}\")\n",
    "            df_scores.loc[i] = [clf, outer_data, inner_data, acc]\n",
    "            i += 1\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "       & test &  non\\_europe &  toefl \\\\\n",
      "model & train &             &        \\\\\n",
      "\\midrule\n",
      "bigbird & non\\_europe &       0.492 &  0.044 \\\\\n",
      "       & toefl &       0.045 &  0.190 \\\\\n",
      "bigbird\\_fine\\_tuned & non\\_europe &       0.645 &  0.052 \\\\\n",
      "       & toefl &       0.040 &  0.170 \\\\\n",
      "normal & non\\_europe &       0.462 &  0.054 \\\\\n",
      "       & toefl &       0.043 &  0.172 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_scores.pivot(index=[\"model\", \"train\"], columns=[\"test\"], values=\"accuracy\").round(3).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ipykernel)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
